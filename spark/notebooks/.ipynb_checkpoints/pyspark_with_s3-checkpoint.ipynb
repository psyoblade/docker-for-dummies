{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "credentials_config_object = ConfigParser()\n",
    "credentials_config_object.read(\"/home/jovyan/.aws/credentials\")\n",
    "credentials = credentials_config_object[\"default\"]\n",
    "\n",
    "config_object = ConfigParser()\n",
    "config_object.read(\"/home/jovyan/.aws/config\")\n",
    "config = config_object[\"default\"]\n",
    "\n",
    "# import os\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.11.769,org.apache.hadoop:hadoop-aws:2.7.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "#     .set(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "#     .set(\"spark.hadoop.fs.s3a.access.key\", credentials.get('aws_access_key_id'))\n",
    "#     .set(\"spark.hadoop.fs.s3a.secret.key\", credentials.get('aws_secret_access_key'))\n",
    "#     .set(\"spark.hadoop.fs.s3a.endpoint\", f\"s3-{config.get('region')}.amazonaws.com\")\n",
    "#     .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "#     .set(\"spark.driver.extraClassPath\", \"/usr/local/spark/jars/aws-java-sdk-1.11.769.jar:/usr/local/spark/jars/hadoop-aws-2.7.4.jar\")\n",
    "#     .set(\"com.amazonaws.services.s3.enableV4\", True)\n",
    "#     .set(\"spark.driver.extraJavaOptions\", \"-Dcom.amazonaws.services.s3.enableV4=true\")\n",
    "    .set(\"fs.s3n.awsAccessKeyId\", credentials.get('aws_access_key_id'))\n",
    "    .set(\"fs.s3n.awsSecretAccessKey\", credentials.get('aws_secret_access_key'))\n",
    ")\n",
    "sc = SparkContext(conf=conf).getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet(\"s3n://psyoblade-fluentd/parquet/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------------+\n",
      "|  name|favorite_color|favorite_numbers|\n",
      "+------+--------------+----------------+\n",
      "|Alyssa|          null|  [3, 9, 15, 20]|\n",
      "|   Ben|           red|              []|\n",
      "+------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
